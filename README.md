# NexusCache

<div align="center">

![Go Version](https://img.shields.io/badge/Go-1.24+-00ADD8?style=flat&logo=go)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat&logo=docker)

**A high-performance distributed caching system built in Go**

_Inspired by GroupCache, enhanced with etcd service discovery, gRPC communication, cache expiration, and hot data replication_

[Quick Start](#quick-start) â€¢
[Architecture](#architecture) â€¢
[Benchmarks](#benchmarks) â€¢
[Monitoring](#monitoring)

</div>

---

## âœ¨ Features

- **Distributed Caching**: Multi-node cache with consistent hashing for even key distribution
- **Service Discovery**: Dynamic node registration and discovery via etcd
- **gRPC Communication**: High-performance binary protocol for inter-node requests
- **Cache Expiration (TTL)**: Automatic expiration with randomized jitter to prevent stampedes
- **Hot Data Replication**: Frequently accessed data replicated across all nodes
- **Singleflight**: Request deduplication to prevent cache stampedes
- **LRU Eviction**: Least Recently Used eviction when memory limit is reached
- **Prometheus Metrics**: Built-in observability with cache hit rates, latency percentiles

---

## ğŸš€ Quick Start

### One-Command Demo (Docker)

```bash
# Clone the repository
git clone https://github.com/yourusername/nexuscache.git
cd nexuscache

# Start 3-node cluster with etcd, Prometheus, and Grafana
docker-compose up --build

# Wait for services to start (about 30 seconds)
```

### Test the Cache

```bash
# Set a value
curl -X POST "http://localhost:9999/api/set" \
  -d "key=user1&value=John Doe&expire=5&hot=false"

# Get the value
curl "http://localhost:9999/api/get?key=user1"
# Output: value=John Doe

# Set hot data (replicated to all nodes)
curl -X POST "http://localhost:9999/api/set" \
  -d "key=popular&value=Hot Data!&expire=5&hot=true"

# Access from any node
curl "http://localhost:9997/api/get?key=popular"  # Node 3
curl "http://localhost:9998/api/get?key=popular"  # Node 2
```

### Access Monitoring

- **Grafana Dashboard**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9090
- **Node 1 API**: http://localhost:9999
- **Node 2 API**: http://localhost:9998
- **Node 3 API**: http://localhost:9997

---

## ğŸ“Š Benchmarks

Run the benchmark suite:

```bash
cd benchmark
go run load_test.go -duration=30s -concurrency=100 -keys=1000
```

### Sample Results (3-Node Cluster)

| Metric             | Value           |
| ------------------ | --------------- |
| **Throughput**     | 25,000+ ops/sec |
| **Cache Hit Rate** | 95%+            |
| **Latency (p50)**  | 1.2ms           |
| **Latency (p95)**  | 4.5ms           |
| **Latency (p99)**  | 8.2ms           |

_Results vary based on hardware. Tested on: 4-core CPU, 16GB RAM, Docker Desktop_

---

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              Client Request              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           HTTP API Gateway               â”‚
                    â”‚              (Port 9999)                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚                 â”‚
                    â–¼                 â–¼                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Node 1  â”‚â”€â”€â”€â”€â–¶â”‚   Node 2  â”‚â”€â”€â”€â”€â–¶â”‚   Node 3  â”‚
            â”‚  (svc1)   â”‚â—€â”€â”€â”€â”€â”‚  (svc2)   â”‚â—€â”€â”€â”€â”€â”‚  (svc3)   â”‚
            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                  â”‚                 â”‚                 â”‚
                  â”‚     gRPC        â”‚     gRPC        â”‚
                  â”‚                 â”‚                 â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              etcd Cluster                â”‚
                    â”‚        (Service Discovery & Health)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component           | Description                                            |
| ------------------- | ------------------------------------------------------ |
| **Group**           | Cache namespace with getter callback and singleflight  |
| **Consistent Hash** | Virtual nodes (50 per real node) for even distribution |
| **LRU Cache**       | Doubly-linked list + hashmap with TTL support          |
| **gRPC Server**     | Handles remote Get/Set from peer nodes                 |
| **etcd Client**     | Service registration with lease-based health checks    |

---

## ğŸ”§ API Reference

### GET /api/get

Retrieve a cached value.

```bash
curl "http://localhost:9999/api/get?key=mykey"
```

### POST /api/set

Store a value in the cache.

```bash
curl -X POST "http://localhost:9999/api/set" \
  -d "key=mykey&value=myvalue&expire=10&hot=false"
```

| Parameter | Type   | Description                        |
| --------- | ------ | ---------------------------------- |
| `key`     | string | Cache key                          |
| `value`   | string | Value to store                     |
| `expire`  | int    | TTL in minutes (max 4320 = 3 days) |
| `hot`     | bool   | If true, replicate to all nodes    |

### POST /setpeer

Re-add a recovered node to the hash ring.

```bash
curl -X POST "http://localhost:9999/setpeer" -d "peer=svc2"
```

---

## ğŸ“ˆ Monitoring

### Prometheus Metrics

| Metric                                | Type      | Description                            |
| ------------------------------------- | --------- | -------------------------------------- |
| `nexuscache_requests_total`           | Counter   | Total requests by operation and status |
| `nexuscache_request_duration_seconds` | Histogram | Request latency distribution           |
| `nexuscache_cache_size_bytes`         | Gauge     | Current cache memory usage             |
| `nexuscache_peer_requests_total`      | Counter   | Inter-node request count               |

### Grafana Dashboard

Pre-configured dashboard shows:

- Request rate (ops/sec)
- Cache hit rate percentage
- Latency percentiles (p50, p95, p99)
- Total hits, misses, and errors

---

## ğŸ› ï¸ Development

### Prerequisites

- Go 1.24+
- Docker & Docker Compose
- etcd (for local development without Docker)

### Local Development

```bash
# Set environment
export IP_ADDRESS=127.0.0.1

# Start etcd
docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.9 \
  /usr/local/bin/etcd --listen-client-urls http://0.0.0.0:2379 --advertise-client-urls http://127.0.0.1:2379

# Run a single node
go run . --name svc1 --peer svc1 --etcd 127.0.0.1:2379
```

### Run Tests

```bash
go test ./... -v
```

---

## ğŸ“ Project Structure

```
nexuscache/
â”œâ”€â”€ nexuscache/          # Core cache logic
â”‚   â”œâ”€â”€ group.go          # Cache groups with singleflight
â”‚   â”œâ”€â”€ server.go         # gRPC server implementation
â”‚   â”œâ”€â”€ cache.go          # Thread-safe LRU wrapper
â”‚   â””â”€â”€ byteview.go       # Immutable cache value
â”œâ”€â”€ connect/              # Network layer
â”‚   â”œâ”€â”€ register.go       # etcd registration
â”‚   â”œâ”€â”€ discover.go       # Service discovery
â”‚   â”œâ”€â”€ client.go         # gRPC client
â”‚   â””â”€â”€ peers.go          # Peer interfaces
â”œâ”€â”€ consistenthash/       # Consistent hashing
â”œâ”€â”€ lru/                  # LRU cache implementation
â”œâ”€â”€ singleflight/         # Request deduplication
â”œâ”€â”€ metrics/              # Prometheus metrics
â”œâ”€â”€ benchmark/            # Load testing tools
â”œâ”€â”€ grafana/              # Grafana dashboards
â””â”€â”€ docker-compose.yml    # Multi-node deployment
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Inspired by [GroupCache](https://github.com/golang/groupcache) by Brad Fitzpatrick
- Original GeeCache tutorial by [geektutu](https://geektutu.com)
